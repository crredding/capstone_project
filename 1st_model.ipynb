{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import NMF\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_not_starbucks.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 474 entries, 0 to 473\n",
      "Data columns (total 6 columns):\n",
      "location.lat        474 non-null float64\n",
      "location.lng        474 non-null float64\n",
      "name                474 non-null object\n",
      "combined_reviews    474 non-null object\n",
      "num_review_words    474 non-null int64\n",
      "final_address       474 non-null object\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 22.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added LemmaTokenizer to lemmatize words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(strip_accents='unicode',\n",
    "                     tokenizer=LemmaTokenizer(),\n",
    "                     stop_words='english',\n",
    "                     max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tf.fit_transform(data['combined_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=20, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=20)\n",
    "nmf.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nmf.components_\n",
    "W = nmf.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 500)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 20)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['coffee' 'shop' 'good' 'spot' 'bean']\n",
      "1 ['food' 'breakfast' 'egg' 'biscuit' 'burrito']\n",
      "2 ['bagel' 'cheese' 'good' 'sandwich' 'cream']\n",
      "3 ['best' 'espresso' 'latte' 'seattle' 'try']\n",
      "4 ['wa' 'location' 'nice' 'seattle' 'barista']\n",
      "5 ['wifi' 'lot' 'good' 'work' 'beer']\n",
      "6 ['crepe' 'like' 'wanted' 'great' 'stop']\n",
      "7 ['cupcake' 'cake' 'ice' 'cream' 'velvet']\n",
      "8 ['donut' 'doughnut' 'fashioned' 'pot' 'wonderful']\n",
      "9 ['starbucks' 'store' 'located' 'make' 'dont']\n",
      "10 ['great' 'baristas' 'service' 'staff' 'super']\n",
      "11 ['chocolate' 'hot' 'mocha' 'dark' 'shot']\n",
      "12 ['croissant' 'pastry' 'good' 'amazing' 'baked']\n",
      "13 ['neighborhood' 'friendly' 'owner' 'shop' 'little']\n",
      "14 ['sandwich' 'breakfast' 'salad' 'delicious' 'soup']\n",
      "15 ['waffle' 'beer' 'delicious' 'coffee' 'cafe']\n",
      "16 ['place' 'market' 'customer' 'pike' 'day']\n",
      "17 ['lunch' 'dog' 'special' 'chip' 'food']\n",
      "18 ['line' 'stand' 'service' 'order' 'fast']\n",
      "19 ['pizza' 'salad' 'food' 'building' 'card']\n"
     ]
    }
   ],
   "source": [
    "top_words_index = np.argsort(-H)[:,0:5]\n",
    "most_common_words_per_topic = np.array(words)[top_words_index]\n",
    "for i, items in enumerate(most_common_words_per_topic):\n",
    "    print(i, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['Victrola',\n",
       "              'Victrola Cafe and Roastery',\n",
       "              'Voxx Coffee',\n",
       "              'Zoka Coffee'],\n",
       "             1: ['Seattle Central Grind',\n",
       "              'Solsticio',\n",
       "              'Stone Way Café',\n",
       "              \"Terry's 14 Carrot Cafe\"],\n",
       "             2: ['Fat Ducks Deli & Bakery',\n",
       "              'Grateful Bread Baking Company & Cafe',\n",
       "              \"Lama G's\",\n",
       "              'Meadow Brew'],\n",
       "             3: ['Realfine Coffee',\n",
       "              'UW: Reboot Café',\n",
       "              'Uptown Espresso',\n",
       "              'Vero Cafe'],\n",
       "             4: ['The Living Room - GC UD',\n",
       "              'The Seattle Grind',\n",
       "              'Urban Coffee House',\n",
       "              'Visions Espresso Service'],\n",
       "             5: ['Voxx Coffee',\n",
       "              'Wayward Coffeehouse',\n",
       "              'Woodland Coffee',\n",
       "              'Zoka Coffee Roaster & Tea Company'],\n",
       "             6: ['Joe Bar',\n",
       "              'Le Petite Cafe',\n",
       "              'Pearls Tea & Coffee',\n",
       "              \"Seattle's Best Coffee - Retail Cafes- Down\"],\n",
       "             7: ['Cupcake Royale and Verite Coffee',\n",
       "              'Cupcake Royale and Vérité Coffee',\n",
       "              'Pineapple Espresso & Bar',\n",
       "              'The Yellow Leaf Cupcake Co'],\n",
       "             8: ['Top Pot Doughnuts',\n",
       "              'Top Pot Doughnuts',\n",
       "              'Top Pot Doughnuts',\n",
       "              'Top Pot Doughnuts'],\n",
       "             9: ['Starbucks Reserve Roastery & Tasting Room',\n",
       "              'Team Refreshers & Doubleshot',\n",
       "              \"Tully's Coffee\",\n",
       "              \"Tully's Coffee\"],\n",
       "             10: ['Street Bean Espresso',\n",
       "              'The Wick',\n",
       "              'Tougo Coffee Co.',\n",
       "              'UW: Husky Grind'],\n",
       "             11: [\"Tully's Coffee\",\n",
       "              \"Tully's Coffee\",\n",
       "              'Uptown Espresso Gameporium  - Delridge',\n",
       "              'Zeitgeist Kunst & Kaffee'],\n",
       "             12: [\"Nielsen's Pastries\",\n",
       "              'Repast',\n",
       "              \"Specialty's Café & Bakery\",\n",
       "              'Sugar Bakery + Cafe'],\n",
       "             13: ['The Daily Dose',\n",
       "              \"The Scoop at Walter's\",\n",
       "              'Tin Umbrella Coffee',\n",
       "              'Van Gogh Coffee'],\n",
       "             14: ['Seattle Aquarium Cafe',\n",
       "              'The Station',\n",
       "              'Treehouse Coffee',\n",
       "              'Trinity Market'],\n",
       "             15: ['Moore Coffee', 'Métier', 'Sweet Iron Waffles', 'Toast'],\n",
       "             16: ['The Highlands',\n",
       "              \"Tully's Coffee\",\n",
       "              \"Tully's Coffee\",\n",
       "              'UW: Husky Grind'],\n",
       "             17: ['Lucca Espresso',\n",
       "              'Petra Mediterranean Bistro',\n",
       "              'Pico Café',\n",
       "              'Third Ave Cafe'],\n",
       "             18: ['Specialty’s Café & Bakery',\n",
       "              'Suzzallo Espresso',\n",
       "              'UWMC Lobby Espresso',\n",
       "              'West Bay Espresso'],\n",
       "             19: ['Rococo Coffee Roasting',\n",
       "              'Starbucks Secure Access Sodo 8',\n",
       "              \"Tully's Coffee\",\n",
       "              'Tutta Bella Neapolitan Pizzeria']})"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def top_shops(W):\n",
    "shop_dict = defaultdict(list)\n",
    "for index, item in enumerate(W):\n",
    "    key = np.argmax(item)\n",
    "    value = item[key]\n",
    "    name = data['name'][index]\n",
    "    shop_dict[key].append([value, name])\n",
    "top_shop_names = defaultdict(list)\n",
    "for feature in shop_dict:\n",
    "    top_shop_names[feature] = list(np.sort(np.array(shop_dict[feature]).T)[1,-5:-1])\n",
    "top_shop_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
