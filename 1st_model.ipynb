{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import NMF\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_not_starbucks.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 474 entries, 0 to 473\n",
      "Data columns (total 6 columns):\n",
      "location.lat        474 non-null float64\n",
      "location.lng        474 non-null float64\n",
      "name                474 non-null object\n",
      "combined_reviews    474 non-null object\n",
      "num_review_words    474 non-null int64\n",
      "final_address       474 non-null object\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 22.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out shops with less than 20 words in their review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "over20_data = data[data['num_review_words'] >= 20].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding custom stopwords to sklearns defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = list(stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords += ['coffee', 'shop', 'coffeeshop', 'starbucks', 'wa', 'seattle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added LemmaTokenizer to lemmatize words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(strip_accents='unicode',\n",
    "                     tokenizer=LemmaTokenizer(),\n",
    "                     stop_words=stopwords,\n",
    "                     max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tf.fit_transform(over20_data['combined_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=20, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=20)\n",
    "nmf.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nmf.components_\n",
    "W = nmf.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 500)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 20)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['good' 'friendly' 'staff' 'cute' 'neighborhood']\n",
      "1 ['sandwich' 'breakfast' 'delicious' 'soup' 'egg']\n",
      "2 ['latte' 'best' 'espresso' 'mocha' 'white']\n",
      "3 ['bagel' 'cheese' 'good' 'cream' 'breakfast']\n",
      "4 ['crepe' 'like' 'wanted' 'stop' 'neighborhood']\n",
      "5 ['cupcake' 'cake' 'ice' 'cream' 'pizza']\n",
      "6 ['stand' 'time' 'barista' 'girl' 'drink']\n",
      "7 ['lot' 'work' 'place' 'wifi' 'beer']\n",
      "8 ['donut' 'doughnut' 'fashioned' 'pot' 'old']\n",
      "9 ['croissant' 'pastry' 'good' 'bakery' 'baked']\n",
      "10 ['chocolate' 'hot' 'mocha' 'dark' 'order']\n",
      "11 ['great' 'service' 'love' 'place' 'people']\n",
      "12 ['brew' 'bean' 'cold' 'espresso' 'pour']\n",
      "13 ['owner' 'neighborhood' 'business' 'local' 'new']\n",
      "14 ['market' 'pike' 'view' 'place' 'day']\n",
      "15 ['waffle' 'beer' 'delicious' 'mean' 'try']\n",
      "16 ['food' 'breakfast' 'egg' 'burrito' 'brunch']\n",
      "17 ['biscuit' 'gravy' 'breakfast' 'worth' 'delicious']\n",
      "18 ['card' 'free' 'drink' 'good' 'almond']\n",
      "19 ['located' 'floor' 'building' 'store' 'center']\n"
     ]
    }
   ],
   "source": [
    "top_words_index = np.argsort(-H)[:,0:5]\n",
    "most_common_words_per_topic = np.array(words)[top_words_index]\n",
    "for i, items in enumerate(most_common_words_per_topic):\n",
    "    print(i, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['The Bridge Coffee House',\n",
       "              'The Seattle Grind',\n",
       "              'Tin Umbrella Coffee',\n",
       "              'UW: Tower Café'],\n",
       "             1: ['Seattle Aquarium Cafe',\n",
       "              'The Station',\n",
       "              'Treehouse Coffee',\n",
       "              'Trinity Market'],\n",
       "             2: ['Uptown Espresso',\n",
       "              'Uptown Espresso Gameporium  - Delridge',\n",
       "              'Vero Cafe',\n",
       "              'Zeitgeist Kunst & Kaffee'],\n",
       "             3: ['Fat Ducks Deli & Bakery',\n",
       "              'Grateful Bread Baking Company & Cafe',\n",
       "              \"Lama G's\",\n",
       "              'Mabel Coffee'],\n",
       "             4: ['Essential Bakery Cafe',\n",
       "              'Joe Bar',\n",
       "              'Le Petite Cafe',\n",
       "              'Pearls Tea & Coffee'],\n",
       "             5: ['Cupcake Royale and Verite Coffee',\n",
       "              'Cupcake Royale and Vérité Coffee',\n",
       "              'Pineapple Espresso & Bar',\n",
       "              'The Yellow Leaf Cupcake Co'],\n",
       "             6: ['UW: Husky Grind',\n",
       "              'West Bay Espresso',\n",
       "              'Zoo Java',\n",
       "              'ladybug espresso'],\n",
       "             7: ['Victrola',\n",
       "              'Wayward Coffeehouse',\n",
       "              'Woodland Coffee',\n",
       "              'Zoka Coffee Roaster & Tea Company'],\n",
       "             8: ['Top Pot Doughnuts',\n",
       "              'Top Pot Doughnuts',\n",
       "              'Top Pot Doughnuts',\n",
       "              'Top Pot Doughnuts'],\n",
       "             9: ['Repast',\n",
       "              \"Specialty's Café & Bakery\",\n",
       "              'Standard Bakery',\n",
       "              'Storyville Coffee Company'],\n",
       "             10: ['Storyville Coffee Company',\n",
       "              'Suzzallo Espresso',\n",
       "              'True North Coffee',\n",
       "              \"Tully's - Pioneer Square\"],\n",
       "             11: ['Van Gogh Coffee',\n",
       "              'Visions Espresso Service',\n",
       "              'Voxx Coffee',\n",
       "              'Voxx Coffee'],\n",
       "             12: ['Starbucks Reserve Roastery & Tasting Room',\n",
       "              'Stumptown Coffee Roasters',\n",
       "              'Ventoux Cafe & Hart Roasters',\n",
       "              'Victrola Cafe and Roastery'],\n",
       "             13: ['Revolutions Coffee',\n",
       "              'S + L',\n",
       "              'Sound & Fog',\n",
       "              \"The Scoop at Walter's\"],\n",
       "             14: ['Seven Coffee Roasters',\n",
       "              'Storyville Coffee Company',\n",
       "              'The Bistro at Aljoya',\n",
       "              \"Tully's Coffee\"],\n",
       "             15: ['Empire Espresso',\n",
       "              'Moore Coffee',\n",
       "              'Métier',\n",
       "              'Sweet Iron Waffles'],\n",
       "             16: ['Stone Way Café',\n",
       "              \"Terry's 14 Carrot Cafe\",\n",
       "              'Third Ave Cafe',\n",
       "              'Tutta Bella Neapolitan Pizzeria'],\n",
       "             17: ['Biscuit & Bean',\n",
       "              'Biscuit Bitch - Belltown',\n",
       "              'Caffé Lieto',\n",
       "              'Cuppajo On The Go'],\n",
       "             18: ['Sip and Ship',\n",
       "              \"Tully's Coffee\",\n",
       "              \"Tully's Coffee\",\n",
       "              \"Tully's Coffee\"],\n",
       "             19: ['Team Refreshers & Doubleshot',\n",
       "              \"Tully's Coffee\",\n",
       "              \"Tully's Coffee\",\n",
       "              \"Tully's Coffee\"]})"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def top_shops(W):\n",
    "shop_dict = defaultdict(list)\n",
    "for index, item in enumerate(W):\n",
    "    key = np.argmax(item)\n",
    "    value = item[key]\n",
    "    name = over20_data['name'][index]\n",
    "    shop_dict[key].append([value, name])\n",
    "top_shop_names = defaultdict(list)\n",
    "for feature in shop_dict:\n",
    "    top_shop_names[feature] = list(np.sort(np.array(shop_dict[feature]).T)[1,-5:-1])\n",
    "top_shop_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
